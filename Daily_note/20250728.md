# 📘 회귀분석 개념 정리

## 1. 회귀분석이 가능한 조건

* **입력 데이터**: 2차원의 정형화된 구조 (예: 행 = 샘플, 열 = 피처)
* **종속 변수 $y$**: 연속형 데이터

→ 위 조건이 충족되면 **지도학습(Supervised Learning)** 방식의 **회귀분석(Regression Analysis)** 가능

---

## 2. 입력 데이터에 따른 분류

| 구분        | 종속변수 $y$ 존재 여부 | 학습 방식 | 목적           |
| --------- | -------------- | ----- | ------------ |
| 회귀분석      | 있음             | 지도학습  | 예측           |
| 군집/차원축소 등 | 없음             | 비지도학습 | 유사성 / 연관성 파악 |

* **y가 없을 경우**:

  * **행 간 유사성** → 클러스터링 (예: K-means)
  * **열 간 연관성** → 연관규칙 분석 (예: Apriori)

---

## 3. 회귀분석의 핵심 아이디어

* 회귀분석은 입력 피처(x)들과 출력(y) 사이에 **평균적 성향**이 존재한다고 가정
* **하지만 항상 성향이 드러나지는 않음**

  * 이때는 데이터가 회귀모델 가정에 **부합하지 않는 경우**가 많음

---

## 4. 회귀모델의 주요 가정 (모형 진단 관점)

| 가정 항목           | 설명                  | 점검 방법                       |
| --------------- | ------------------- | --------------------------- |
| (1) 인과/선형 관계    | $x \to y$ 방향성 및 선형성 | 상관분석 (Correlation)          |
| (2) 독립 변수 간 독립성 | X들끼리 다중공선성 없어야 함    | 분산팽창계수(VIF), 카이제곱 검정        |
| (3) 잔차의 무작위성    | 잔차에 패턴이 없어야 함       | 잔차 플롯 (Residual Plot) 등 시각화 |

---

## 5. 회귀 모델의 수학적 구조

* 회귀방정식:

  $$
  \hat{y} = w_0 + w_1x_1 + w_2x_2 + \cdots + w_nx_n
  $$
* n개의 입력 $x_1, ..., x_n$를 받아 **1개의 예측값 $\hat{y}$** 출력
* ⇒ 흔히 \*\*“n차원에서 1차원으로의 매핑”\*\*이라 표현됨
  ❗ 단, 이는 **PCA와 같은 차원 축소와는 개념이 다름**
  → 회귀는 **설명력과 예측**이 목적, **차원 축소 자체가 목적 아님**

---

## 6. 학습의 목표 = 최적의 W 찾기

* 모델이 학습되는 과정:

  $$
  \text{최적의 가중치 } W = \arg\min \text{Cost}(W)
  $$
* Cost Function 예:

  $$
  \text{MSE} = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2
  $$

---

## 7. 최적화를 위한 방법: 경사하강법 (Gradient Descent)

* 목적: **오차(Cost)를 최소화**하는 방향으로 가중치 $W$ 업데이트
* 방법:

  1. 임의의 $W$로 시작
  2. Cost function의 **기울기(Gradient)** 계산
  3. **기울기가 0에 수렴할 때까지** 업데이트
* 특징:

  * 항상 Cost를 감소시키는 방향
  * **학습률(learning rate)** 설정이 매우 중요

---

## ✅ 정리

* 회귀분석은 **정형화된 입력 + 연속형 타깃**이 있을 때 사용 가능
* 회귀모델이 유효하려면 \*\*세 가지 가정(선형성, 독립성, 잔차의 무작위성)\*\*을 만족해야 함
* 학습의 핵심은 **최적의 W를 찾아 예측 정확도를 높이는 것**
* **경사하강법**은 이를 위한 대표적인 최적화 방법

